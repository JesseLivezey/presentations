{
 "metadata": {
  "name": "",
  "signature": "sha256:222c667ae45f8a14c5e1bdbc3e964dbb574f8907353ee5a3fe01f503a75c8524"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "from numbapro import cuda\n",
      "from numbapro.cudalib import cublas\n",
      "from math import ceil\n",
      "import matplotlib.pyplot as plt\n",
      "%matplotlib inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 43
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Problems that can be mapped to GPUs"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- Many slow threads can be run at once\n",
      "- Elementwise operations are trivial\n",
      "- Functions that can be written as independent threads are easy\n",
      "- Functions that can be written as independent threads with sync points require more work\n",
      "- Otherwise, GPUs might not be the right tool"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Elementwise Addition"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "@cuda.jit('void(f4[:,:], f4[:,:], f4[:,:])')\n",
      "def add(a, b, c):\n",
      "    n,m = a.shape\n",
      "    i,j = cuda.grid(2)\n",
      "    \n",
      "    if i<n and j<m:\n",
      "        c[i,j] = a[i,j]+b[i,j]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dim = 4096\n",
      "nIter = 100\n",
      "shape = (dim, dim)\n",
      "a = np.ones(shape).astype(np.float32)\n",
      "b = (2.*np.ones(shape)).astype(np.float32)\n",
      "c = np.zeros(shape).astype(np.float32)\n",
      "\n",
      "stream = cuda.stream()\n",
      "blas = cublas.Blas(stream)\n",
      "d_a = cuda.to_device(np.array(a, dtype=np.float32, order='F'),\n",
      "                     stream=stream)\n",
      "d_b = cuda.to_device(np.array(b, dtype=np.float32, order='F'),\n",
      "                     stream=stream)\n",
      "d_c = cuda.to_device(np.array(c, dtype=np.float32, order='F'),\n",
      "                     stream=stream)\n",
      "stream.synchronize()\n",
      "\n",
      "blockdim2 = (32,32)\n",
      "griddim2 = (int(ceil(shape[0]/float(blockdim2[0]))),\n",
      "            int(ceil(shape[1]/float(blockdim2[1]))))\n",
      "\n",
      "def np_loop(a, b, c, nIter):\n",
      "    for ii in xrange(nIter):\n",
      "        c[:] = a+b\n",
      "    return\n",
      "def cu_loop(d_a, d_b, d_c, nIter, griddim2, blockdim2, stream):\n",
      "    for ii in xrange(nIter):\n",
      "        add[griddim2,blockdim2, stream](d_a, d_b, d_c)\n",
      "    stream.synchronize()\n",
      "    return \n",
      "def bl_loop(d_a, d_b, d_c, nIter, stream):\n",
      "    for ii in xrange(nIter):\n",
      "        blas.geam('N', 'N', dim, dim, 1., d_a, 1., d_b, d_c)\n",
      "    stream.synchronize()\n",
      "    return"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "c[:] = a+b\n",
      "np.allclose(c, 3)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "True"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "add[griddim2,blockdim2, stream](d_a, d_b, d_c)\n",
      "np.allclose(d_c.copy_to_host(), 3)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 12,
       "text": [
        "True"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "blas.geam('N', 'N', dim, dim, 1., d_a, 1., d_b, d_c)\n",
      "np.allclose(d_c.copy_to_host(), 3)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 13,
       "text": [
        "True"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%timeit np_loop(a, b, c, nIter)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1 loops, best of 3: 2.84 s per loop\n"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%timeit cu_loop(d_a, d_b, d_c, nIter, griddim2,blockdim2, stream)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1 loops, best of 3: 673 ms per loop\n"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%timeit bl_loop(d_a, d_b, d_c, nIter, stream)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "10 loops, best of 3: 112 ms per loop\n"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Implementing LCA on GPU"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- Form of NumbaPro CUDA kernels\n",
      "- Calling BLAS routines\n",
      "- Writing a GPU kernel"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "LCA infers the sparse coefficients for the basis functions using the differential equation:\n",
      "$$u_i(t) = u_i(t-1)+\\eta(b_i-s_j(t-1)c_{ji}-u(t-1))$$\n",
      "and the thresholds\n",
      "$$s_i(t) = T(u_i(t))$$\n",
      "where\n",
      "$$b_i = \\phi_i\\cdot x$$\n",
      "and\n",
      "$$c_{ji} = \\phi_j\\cdot\\phi_i;\\ j\\neq i$$\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "@cuda.jit('void(f4[:,:])')\n",
      "def csub(c):\n",
      "    n = c.shape[0]\n",
      "    i = cuda.grid(1)\n",
      "    \n",
      "    if i<n and i>=0:\n",
      "        c[i,i] = 0."
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "@cuda.jit('void(f4[:,:],f4[:,:],f4[:,:],f4[:,:],f4,f4[:])')\n",
      "def iterate(b,ci,u,s,eta,thresh,):\n",
      "    n = u.shape[0]\n",
      "    m = u.shape[1]\n",
      "    i,j = cuda.grid(2)\n",
      "    \n",
      "    if i<n and j<m:\n",
      "        # Integrate one timestep\n",
      "        u[i,j] = eta*(b[i,j]-ci[i,j])+(1-eta)*u[i,j]\n",
      "        # Threshold\n",
      "        if u[i,j] < thresh[i] and u[i,j] > -thresh[i]:\n",
      "            s[i,j] = 0.\n",
      "        else:\n",
      "            s[i,j] = u[i,j]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 47
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def infer(dictionary,stimuli,eta,nIter):\n",
      "#Get Blas routines\n",
      "    blas = cublas.Blas()\n",
      "#Initialize arrays\n",
      "    nDict = dictionary.shape[0]\n",
      "    nStim = stimuli.shape[0]\n",
      "    nFeat = stimuli.shape[1]\n",
      "    # Create zeros arrays and move to GPU\n",
      "    d_u = cuda.to_device(np.zeros((nStim,nDict),\n",
      "                                  dtype=np.float32,order='F'))\n",
      "    d_s = cuda.to_device(np.zeros((nStim,nDict),\n",
      "                                  dtype=np.float32,order='F'))\n",
      "    d_b = cuda.to_device(np.zeros((nStim,nDict),\n",
      "                                  dtype=np.float32,order='F'))\n",
      "    d_ci = cuda.to_device(np.zeros((nStim,nDict),\n",
      "                                   dtype=np.float32,order='F'))\n",
      "    d_c = cuda.to_device(np.zeros((nDict,nDict),\n",
      "                                  dtype=np.float32,order='F'))\n",
      "    \n",
      "    # Move inputs to GPU\n",
      "    d_dictionary = cuda.to_device(np.array(dictionary,\n",
      "                                           dtype=np.float32,order='F'))\n",
      "    d_stimuli = cuda.to_device(np.array(stimuli,\n",
      "                                        dtype=np.float32,order='F'))\n",
      "\n",
      "    blockdim2 = (32,32)\n",
      "    blockdim1 = 32\n",
      "    griddimcsub = int(ceil(nDict/float(blockdim1)))\n",
      "    griddimi = (int(ceil(nStim/float(blockdim2[0]))),\n",
      "                int(ceil(nDict/float(blockdim2[1]))))\n",
      "    \n",
      "    # Calculate c: overlap of basis functions\n",
      "    # with each other minus identity\n",
      "    blas.gemm('N','T',nDict,nDict,nFeat,1.,\n",
      "              d_dictionary,d_dictionary,0.,d_c)\n",
      "    csub[griddimcsub,blockdim1](d_c)\n",
      "    # Calculate b: overlap of basis functions\n",
      "    # and data\n",
      "    blas.gemm('N','T',nStim,nDict,nFeat,1.,d_stimuli,\n",
      "              d_dictionary,0.,d_b)\n",
      "    thresh = np.mean(np.absolute(d_b.copy_to_host()),axis=1)\n",
      "    d_thresh = cuda.to_device(thresh)\n",
      "    # Update u[i] and s[i] for nIter time steps\n",
      "    for kk in xrange(nIter):\n",
      "        # Calculate ci: amount other neurons are stimulated\n",
      "        # times overlap with rest of basis\n",
      "        blas.gemm('N','N',nStim,nDict,nDict,1.,d_s,d_c,0.,d_ci)\n",
      "        iterate[griddimi,blockdim2](d_b,d_ci,d_u,d_s,eta,d_thresh)\n",
      "    u = d_u.copy_to_host()\n",
      "    s = d_s.copy_to_host()\n",
      "    return (s,u)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 48
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Make some random data and a random dictionary\n",
      "data = np.random.randn(50,100)\n",
      "dictionary = np.random.randn(1000,100)\n",
      "dictionary = np.diag(np.sqrt(1./(dictionary*\n",
      "                                 dictionary).sum(axis=1))).dot(dictionary)\n",
      "eta = .01\n",
      "nIter = 500"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 49
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "s, u = infer(dictionary, data, eta, nIter)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 50
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.plot(u.ravel(),s.ravel(), '.')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 51,
       "text": [
        "[<matplotlib.lines.Line2D at 0x7f9f566f5150>]"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAEACAYAAACqOy3+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nx87n76QNrrkAAAAASUVORK5CYII=\n",
       "text": [
        "<matplotlib.figure.Figure at 0x7f9f5684ecd0>"
       ]
      }
     ],
     "prompt_number": 51
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}